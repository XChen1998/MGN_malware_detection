@crypt.buff = internal global [20 x i8] zeroinitializer, align 16
@con_salt = internal global [128 x i8] c"\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\00\01\02\03\04\05\06\07\08\09\0A\0B\05\06\07\08\09\0A\0B\0C\0D\0E\0F\10\11\12\13\14\15\16\17\18\19\1A\1B\1C\1D\1E\1F !\22#$% !\22#$%&'()*+,-./0123456789:;<=>?\00\00\00\00\00", align 16
@cov_2char = internal global [64 x i8] c"./0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz", align 16
@shifts2 = internal global [16 x i8] c"\00\00\01\01\01\01\01\01\00\01\01\01\01\01\01\00", align 16
@skb = internal global [8 x [64 x i64]] [[64 x i64] [i64 0, i64 16, i64 536870912, i64 536870928, i64 65536, i64 65552, i64 536936448, i64 536936464, i64 2048, i64 2064, i64 536872960, i64 536872976, i64 67584, i64 67600, i64 536938496, i64 536938512, i64 32, i64 48, i64 536870944, i64 536870960, i64 65568, i64 65584, i64 536936480, i64 536936496, i64 2080, i64 2096, i64 536872992, i64 536873008, i64 67616, i64 67632, i64 536938528, i64 536938544, i64 524288, i64 524304, i64 537395200, i64 537395216, i64 589824, i64 589840, i64 537460736, i64 537460752, i64 526336, i64 526352, i64 537397248, i64 537397264, i64 591872, i64 591888, i64 537462784, i64 537462800, i64 524320, i64 524336, i64 537395232, i64 537395248, i64 589856, i64 589872, i64 537460768, i64 537460784, i64 526368, i64 526384, i64 537397280, i64 537397296, i64 591904, i64 591920, i64 537462816, i64 537462832], [64 x i64] [i64 0, i64 33554432, i64 8192, i64 33562624, i64 2097152, i64 35651584, i64 2105344, i64 35659776, i64 4, i64 33554436, i64 8196, i64 33562628, i64 2097156, i64 35651588, i64 2105348, i64 35659780, i64 1024, i64 33555456, i64 9216, i64 33563648, i64 2098176, i64 35652608, i64 2106368, i64 35660800, i64 1028, i64 33555460, i64 9220, i64 33563652, i64 2098180, i64 35652612, i64 2106372, i64 35660804, i64 268435456, i64 301989888, i64 268443648, i64 301998080, i64 270532608, i64 304087040, i64 270540800, i64 304095232, i64 268435460, i64 301989892, i64 268443652, i64 301998084, i64 270532612, i64 304087044, i64 270540804, i64 304095236, i64 268436480, i64 301990912, i64 268444672, i64 301999104, i64 270533632, i64 304088064, i64 270541824, i64 304096256, i64 268436484, i64 301990916, i64 268444676, i64 301999108, i64 270533636, i64 304088068, i64 270541828, i64 304096260], [64 x i64] [i64 0, i64 1, i64 262144, i64 262145, i64 16777216, i64 16777217, i64 17039360, i64 17039361, i64 2, i64 3, i64 262146, i64 262147, i64 16777218, i64 16777219, i64 17039362, i64 17039363, i64 512, i64 513, i64 262656, i64 262657, i64 16777728, i64 16777729, i64 17039872, i64 17039873, i64 514, i64 515, i64 262658, i64 262659, i64 16777730, i64 16777731, i64 17039874, i64 17039875, i64 134217728, i64 134217729, i64 134479872, i64 134479873, i64 150994944, i64 150994945, i64 151257088, i64 151257089, i64 134217730, i64 134217731, i64 134479874, i64 134479875, i64 150994946, i64 150994947, i64 151257090, i64 151257091, i64 134218240, i64 134218241, i64 134480384, i64 134480385, i64 150995456, i64 150995457, i64 151257600, i64 151257601, i64 134218242, i64 134218243, i64 134480386, i64 134480387, i64 150995458, i64 150995459, i64 151257602, i64 151257603], [64 x i64] [i64 0, i64 1048576, i64 256, i64 1048832, i64 8, i64 1048584, i64 264, i64 1048840, i64 4096, i64 1052672, i64 4352, i64 1052928, i64 4104, i64 1052680, i64 4360, i64 1052936, i64 67108864, i64 68157440, i64 67109120, i64 68157696, i64 67108872, i64 68157448, i64 67109128, i64 68157704, i64 67112960, i64 68161536, i64 67113216, i64 68161792, i64 67112968, i64 68161544, i64 67113224, i64 68161800, i64 131072, i64 1179648, i64 131328, i64 1179904, i64 131080, i64 1179656, i64 131336, i64 1179912, i64 135168, i64 1183744, i64 135424, i64 1184000, i64 135176, i64 1183752, i64 135432, i64 1184008, i64 67239936, i64 68288512, i64 67240192, i64 68288768, i64 67239944, i64 68288520, i64 67240200, i64 68288776, i64 67244032, i64 68292608, i64 67244288, i64 68292864, i64 67244040, i64 68292616, i64 67244296, i64 68292872], [64 x i64] [i64 0, i64 268435456, i64 65536, i64 268500992, i64 4, i64 268435460, i64 65540, i64 268500996, i64 536870912, i64 805306368, i64 536936448, i64 805371904, i64 536870916, i64 805306372, i64 536936452, i64 805371908, i64 1048576, i64 269484032, i64 1114112, i64 269549568, i64 1048580, i64 269484036, i64 1114116, i64 269549572, i64 537919488, i64 806354944, i64 537985024, i64 806420480, i64 537919492, i64 806354948, i64 537985028, i64 806420484, i64 4096, i64 268439552, i64 69632, i64 268505088, i64 4100, i64 268439556, i64 69636, i64 268505092, i64 536875008, i64 805310464, i64 536940544, i64 805376000, i64 536875012, i64 805310468, i64 536940548, i64 805376004, i64 1052672, i64 269488128, i64 1118208, i64 269553664, i64 1052676, i64 269488132, i64 1118212, i64 269553668, i64 537923584, i64 806359040, i64 537989120, i64 806424576, i64 537923588, i64 806359044, i64 537989124, i64 806424580], [64 x i64] [i64 0, i64 134217728, i64 8, i64 134217736, i64 1024, i64 134218752, i64 1032, i64 134218760, i64 131072, i64 134348800, i64 131080, i64 134348808, i64 132096, i64 134349824, i64 132104, i64 134349832, i64 1, i64 134217729, i64 9, i64 134217737, i64 1025, i64 134218753, i64 1033, i64 134218761, i64 131073, i64 134348801, i64 131081, i64 134348809, i64 132097, i64 134349825, i64 132105, i64 134349833, i64 33554432, i64 167772160, i64 33554440, i64 167772168, i64 33555456, i64 167773184, i64 33555464, i64 167773192, i64 33685504, i64 167903232, i64 33685512, i64 167903240, i64 33686528, i64 167904256, i64 33686536, i64 167904264, i64 33554433, i64 167772161, i64 33554441, i64 167772169, i64 33555457, i64 167773185, i64 33555465, i64 167773193, i64 33685505, i64 167903233, i64 33685513, i64 167903241, i64 33686529, i64 167904257, i64 33686537, i64 167904265], [64 x i64] [i64 0, i64 256, i64 524288, i64 524544, i64 16777216, i64 16777472, i64 17301504, i64 17301760, i64 16, i64 272, i64 524304, i64 524560, i64 16777232, i64 16777488, i64 17301520, i64 17301776, i64 2097152, i64 2097408, i64 2621440, i64 2621696, i64 18874368, i64 18874624, i64 19398656, i64 19398912, i64 2097168, i64 2097424, i64 2621456, i64 2621712, i64 18874384, i64 18874640, i64 19398672, i64 19398928, i64 512, i64 768, i64 524800, i64 525056, i64 16777728, i64 16777984, i64 17302016, i64 17302272, i64 528, i64 784, i64 524816, i64 525072, i64 16777744, i64 16778000, i64 17302032, i64 17302288, i64 2097664, i64 2097920, i64 2621952, i64 2622208, i64 18874880, i64 18875136, i64 19399168, i64 19399424, i64 2097680, i64 2097936, i64 2621968, i64 2622224, i64 18874896, i64 18875152, i64 19399184, i64 19399440], [64 x i64] [i64 0, i64 67108864, i64 262144, i64 67371008, i64 2, i64 67108866, i64 262146, i64 67371010, i64 8192, i64 67117056, i64 270336, i64 67379200, i64 8194, i64 67117058, i64 270338, i64 67379202, i64 32, i64 67108896, i64 262176, i64 67371040, i64 34, i64 67108898, i64 262178, i64 67371042, i64 8224, i64 67117088, i64 270368, i64 67379232, i64 8226, i64 67117090, i64 270370, i64 67379234, i64 2048, i64 67110912, i64 264192, i64 67373056, i64 2050, i64 67110914, i64 264194, i64 67373058, i64 10240, i64 67119104, i64 272384, i64 67381248, i64 10242, i64 67119106, i64 272386, i64 67381250, i64 2080, i64 67110944, i64 264224, i64 67373088, i64 2082, i64 67110946, i64 264226, i64 67373090, i64 10272, i64 67119136, i64 272416, i64 67381280, i64 10274, i64 67119138, i64 272418, i64 67381282]], align 16
@SPtrans = internal global [8 x [64 x i64]] [[64 x i64] [i64 8520192, i64 131072, i64 2155872256, i64 2156003840, i64 8388608, i64 2147615232, i64 2147614720, i64 2155872256, i64 2147615232, i64 8520192, i64 8519680, i64 2147484160, i64 2155872768, i64 8388608, i64 0, i64 2147614720, i64 131072, i64 2147483648, i64 8389120, i64 131584, i64 2156003840, i64 8519680, i64 2147484160, i64 8389120, i64 2147483648, i64 512, i64 131584, i64 2156003328, i64 512, i64 2155872768, i64 2156003328, i64 0, i64 0, i64 2156003840, i64 8389120, i64 2147614720, i64 8520192, i64 131072, i64 2147484160, i64 8389120, i64 2156003328, i64 512, i64 131584, i64 2155872256, i64 2147615232, i64 2147483648, i64 2155872256, i64 8519680, i64 2156003840, i64 131584, i64 8519680, i64 2155872768, i64 8388608, i64 2147484160, i64 2147614720, i64 0, i64 131072, i64 8388608, i64 2155872768, i64 8520192, i64 2147483648, i64 2156003328, i64 512, i64 2147615232], [64 x i64] [i64 268705796, i64 0, i64 270336, i64 268697600, i64 268435460, i64 8196, i64 268443648, i64 270336, i64 8192, i64 268697604, i64 4, i64 268443648, i64 262148, i64 268705792, i64 268697600, i64 4, i64 262144, i64 268443652, i64 268697604, i64 8192, i64 270340, i64 268435456, i64 0, i64 262148, i64 268443652, i64 270340, i64 268705792, i64 268435460, i64 268435456, i64 262144, i64 8196, i64 268705796, i64 262148, i64 268705792, i64 268443648, i64 270340, i64 268705796, i64 262148, i64 268435460, i64 0, i64 268435456, i64 8196, i64 262144, i64 268697604, i64 8192, i64 268435456, i64 270340, i64 268443652, i64 268705792, i64 8192, i64 0, i64 268435460, i64 4, i64 268705796, i64 270336, i64 268697600, i64 268697604, i64 262144, i64 8196, i64 268443648, i64 268443652, i64 4, i64 268697600, i64 270336], [64 x i64] [i64 1090519040, i64 16842816, i64 64, i64 1090519104, i64 1073807360, i64 16777216, i64 1090519104, i64 65600, i64 16777280, i64 65536, i64 16842752, i64 1073741824, i64 1090584640, i64 1073741888, i64 1073741824, i64 1090584576, i64 0, i64 1073807360, i64 16842816, i64 64, i64 1073741888, i64 1090584640, i64 65536, i64 1090519040, i64 1090584576, i64 16777280, i64 1073807424, i64 16842752, i64 65600, i64 0, i64 16777216, i64 1073807424, i64 16842816, i64 64, i64 1073741824, i64 65536, i64 1073741888, i64 1073807360, i64 16842752, i64 1090519104, i64 0, i64 16842816, i64 65600, i64 1090584576, i64 1073807360, i64 16777216, i64 1090584640, i64 1073741824, i64 1073807424, i64 1090519040, i64 16777216, i64 1090584640, i64 65536, i64 16777280, i64 1090519104, i64 65600, i64 16777280, i64 0, i64 1090584576, i64 1073741888, i64 1090519040, i64 1073807424, i64 64, i64 16842752], [64 x i64] [i64 1049602, i64 67109888, i64 2, i64 68158466, i64 0, i64 68157440, i64 67109890, i64 1048578, i64 68158464, i64 67108866, i64 67108864, i64 1026, i64 67108866, i64 1049602, i64 1048576, i64 67108864, i64 68157442, i64 1049600, i64 1024, i64 2, i64 1049600, i64 67109890, i64 68157440, i64 1024, i64 1026, i64 0, i64 1048578, i64 68158464, i64 67109888, i64 68157442, i64 68158466, i64 1048576, i64 68157442, i64 1026, i64 1048576, i64 67108866, i64 1049600, i64 67109888, i64 2, i64 68157440, i64 67109890, i64 0, i64 1024, i64 1048578, i64 0, i64 68157442, i64 68158464, i64 1024, i64 67108864, i64 68158466, i64 1049602, i64 1048576, i64 68158466, i64 2, i64 67109888, i64 1049602, i64 1048578, i64 1049600, i64 68157440, i64 67109890, i64 1026, i64 67108864, i64 67108866, i64 68158464], [64 x i64] [i64 33554432, i64 16384, i64 256, i64 33571080, i64 33570824, i64 33554688, i64 16648, i64 33570816, i64 16384, i64 8, i64 33554440, i64 16640, i64 33554696, i64 33570824, i64 33571072, i64 0, i64 16640, i64 33554432, i64 16392, i64 264, i64 33554688, i64 16648, i64 0, i64 33554440, i64 8, i64 33554696, i64 33571080, i64 16392, i64 33570816, i64 256, i64 264, i64 33571072, i64 33571072, i64 33554696, i64 16392, i64 33570816, i64 16384, i64 8, i64 33554440, i64 33554688, i64 33554432, i64 16640, i64 33571080, i64 0, i64 16648, i64 33554432, i64 256, i64 16392, i64 33554696, i64 256, i64 0, i64 33571080, i64 33570824, i64 33571072, i64 264, i64 16384, i64 16640, i64 33570824, i64 33554688, i64 264, i64 8, i64 16648, i64 33570816, i64 33554440], [64 x i64] [i64 536870928, i64 524304, i64 0, i64 537397248, i64 524304, i64 2048, i64 536872976, i64 524288, i64 2064, i64 537397264, i64 526336, i64 536870912, i64 536872960, i64 536870928, i64 537395200, i64 526352, i64 524288, i64 536872976, i64 537395216, i64 0, i64 2048, i64 16, i64 537397248, i64 537395216, i64 537397264, i64 537395200, i64 536870912, i64 2064, i64 16, i64 526336, i64 526352, i64 536872960, i64 2064, i64 536870912, i64 536872960, i64 526352, i64 537397248, i64 524304, i64 0, i64 536872960, i64 536870912, i64 2048, i64 537395216, i64 524288, i64 524304, i64 537397264, i64 526336, i64 16, i64 537397264, i64 526336, i64 524288, i64 536872976, i64 536870928, i64 537395200, i64 526352, i64 0, i64 2048, i64 536870928, i64 536872976, i64 537397248, i64 537395200, i64 2064, i64 16, i64 537395216], [64 x i64] [i64 4096, i64 128, i64 4194432, i64 4194305, i64 4198529, i64 4097, i64 4224, i64 0, i64 4194304, i64 4194433, i64 129, i64 4198400, i64 1, i64 4198528, i64 4198400, i64 129, i64 4194433, i64 4096, i64 4097, i64 4198529, i64 0, i64 4194432, i64 4194305, i64 4224, i64 4198401, i64 4225, i64 4198528, i64 1, i64 4225, i64 4198401, i64 128, i64 4194304, i64 4225, i64 4198400, i64 4198401, i64 129, i64 4096, i64 128, i64 4194304, i64 4198401, i64 4194433, i64 4225, i64 4224, i64 0, i64 128, i64 4194305, i64 1, i64 4194432, i64 0, i64 4194433, i64 4194432, i64 4224, i64 129, i64 4096, i64 4198529, i64 4194304, i64 4198528, i64 1, i64 4097, i64 4198529, i64 4194305, i64 4198528, i64 4198400, i64 4097], [64 x i64] [i64 136314912, i64 136347648, i64 32800, i64 0, i64 134250496, i64 2097184, i64 136314880, i64 136347680, i64 32, i64 134217728, i64 2129920, i64 32800, i64 2129952, i64 134250528, i64 134217760, i64 136314880, i64 32768, i64 2129952, i64 2097184, i64 134250496, i64 136347680, i64 134217760, i64 0, i64 2129920, i64 134217728, i64 2097152, i64 134250528, i64 136314912, i64 2097152, i64 32768, i64 136347648, i64 32, i64 2097152, i64 32768, i64 134217760, i64 136347680, i64 32800, i64 134217728, i64 0, i64 2129920, i64 136314912, i64 134250528, i64 134250496, i64 2097184, i64 136347648, i64 32, i64 2097184, i64 134250496, i64 136347680, i64 2097152, i64 136314880, i64 134217760, i64 2129920, i64 32800, i64 134250528, i64 136314880, i64 32, i64 136347648, i64 2129952, i64 0, i64 134217728, i64 136314912, i64 32768, i64 2129952]], align 16
  %204 = load i64, i64* %l, align 8
  store i64 %204, i64* %t, align 8
  %205 = load i64, i64* %r, align 8
  store i64 %205, i64* %l, align 8
  %206 = load i64, i64* %t, align 8
  store i64 %206, i64* %r, align 8
  %209 = load i32, i32* %j, align 4
  %210 = add nsw i32 %209, 1
  store i32 %210, i32* %j, align 4
  %149 = load i32, i32* %i, align 4
  %150 = sext i32 %149 to i64
  %151 = getelementptr inbounds [16 x i8], [16 x i8]* @shifts2, i64 0, i64 %150
  %152 = load i8, i8* %151, align 1
  %153 = icmp ne i8 %152, 0
  %156 = load i64, i64* %c, align 8
  %157 = lshr i64 %156, 2
  %158 = load i64, i64* %c, align 8
  %159 = shl i64 %158, 26
  %160 = or i64 %157, %159
  store i64 %160, i64* %c, align 8
  %161 = load i64, i64* %d, align 8
  %162 = lshr i64 %161, 2
  %163 = load i64, i64* %d, align 8
  %164 = shl i64 %163, 26
  %165 = or i64 %162, %164
  store i64 %165, i64* %d, align 8
  %166 = load i64, i64* %c, align 8
  %167 = and i64 %166, 268435455
  store i64 %167, i64* %c, align 8
  %168 = load i64, i64* %d, align 8
  %169 = and i64 %168, 268435455
  store i64 %169, i64* %d, align 8
  %170 = load i64, i64* %c, align 8
  %171 = and i64 %170, 63
  %172 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @skb, i64 0, i64 0), i64 0, i64 %171
  %173 = load i64, i64* %172, align 8
  %174 = load i64, i64* %c, align 8
  %175 = lshr i64 %174, 6
  %176 = and i64 %175, 3
  %177 = load i64, i64* %c, align 8
  %178 = lshr i64 %177, 7
  %179 = and i64 %178, 60
  %180 = or i64 %176, %179
  %181 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @skb, i64 0, i64 1), i64 0, i64 %180
  %182 = load i64, i64* %181, align 8
  %183 = or i64 %173, %182
  %184 = load i64, i64* %c, align 8
  %185 = lshr i64 %184, 13
  %186 = and i64 %185, 15
  %187 = load i64, i64* %c, align 8
  %188 = lshr i64 %187, 14
  %189 = and i64 %188, 48
  %190 = or i64 %186, %189
  %191 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @skb, i64 0, i64 2), i64 0, i64 %190
  %192 = load i64, i64* %191, align 8
  %193 = or i64 %183, %192
  %194 = load i64, i64* %c, align 8
  %195 = lshr i64 %194, 20
  %196 = and i64 %195, 1
  %197 = load i64, i64* %c, align 8
  %198 = lshr i64 %197, 21
  %199 = and i64 %198, 6
  %200 = or i64 %196, %199
  %201 = load i64, i64* %c, align 8
  %202 = lshr i64 %201, 22
  %203 = and i64 %202, 56
  %204 = or i64 %200, %203
  %205 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @skb, i64 0, i64 3), i64 0, i64 %204
  %206 = load i64, i64* %205, align 8
  %207 = or i64 %193, %206
  store i64 %207, i64* %s, align 8
  %208 = load i64, i64* %d, align 8
  %209 = and i64 %208, 63
  %210 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @skb, i64 0, i64 4), i64 0, i64 %209
  %211 = load i64, i64* %210, align 8
  %212 = load i64, i64* %d, align 8
  %213 = lshr i64 %212, 7
  %214 = and i64 %213, 3
  %215 = load i64, i64* %d, align 8
  %216 = lshr i64 %215, 8
  %217 = and i64 %216, 60
  %218 = or i64 %214, %217
  %219 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @skb, i64 0, i64 5), i64 0, i64 %218
  %220 = load i64, i64* %219, align 8
  %221 = or i64 %211, %220
  %222 = load i64, i64* %d, align 8
  %223 = lshr i64 %222, 15
  %224 = and i64 %223, 63
  %225 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @skb, i64 0, i64 6), i64 0, i64 %224
  %226 = load i64, i64* %225, align 8
  %227 = or i64 %221, %226
  %228 = load i64, i64* %d, align 8
  %229 = lshr i64 %228, 21
  %230 = and i64 %229, 15
  %231 = load i64, i64* %d, align 8
  %232 = lshr i64 %231, 22
  %233 = and i64 %232, 48
  %234 = or i64 %230, %233
  %235 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @skb, i64 0, i64 7), i64 0, i64 %234
  %236 = load i64, i64* %235, align 8
  %237 = or i64 %227, %236
  store i64 %237, i64* %t, align 8
  %238 = load i64, i64* %t, align 8
  %239 = shl i64 %238, 16
  %240 = load i64, i64* %s, align 8
  %241 = and i64 %240, 65535
  %242 = or i64 %239, %241
  %243 = and i64 %242, 4294967295
  %244 = load i64*, i64** %k, align 8
  %245 = getelementptr inbounds i64, i64* %244, i32 1
  store i64* %245, i64** %k, align 8
  store i64 %243, i64* %244, align 8
  %246 = load i64, i64* %s, align 8
  %247 = lshr i64 %246, 16
  %248 = load i64, i64* %t, align 8
  %249 = and i64 %248, 4294901760
  %250 = or i64 %247, %249
  store i64 %250, i64* %s, align 8
  %251 = load i64, i64* %s, align 8
  %252 = shl i64 %251, 4
  %253 = load i64, i64* %s, align 8
  %254 = lshr i64 %253, 28
  %255 = or i64 %252, %254
  store i64 %255, i64* %s, align 8
  %256 = load i64, i64* %s, align 8
  %257 = and i64 %256, 4294967295
  %258 = load i64*, i64** %k, align 8
  %259 = getelementptr inbounds i64, i64* %258, i32 1
  store i64* %259, i64** %k, align 8
  store i64 %257, i64* %258, align 8
  %22 = load i64, i64* %r, align 8
  %23 = load i64, i64* %r, align 8
  %24 = lshr i64 %23, 16
  %25 = xor i64 %22, %24
  store i64 %25, i64* %t, align 8
  %26 = load i64, i64* %t, align 8
  %27 = load i64, i64* %E0, align 8
  %28 = and i64 %26, %27
  store i64 %28, i64* %u, align 8
  %29 = load i64, i64* %t, align 8
  %30 = load i64, i64* %E1, align 8
  %31 = and i64 %29, %30
  store i64 %31, i64* %t, align 8
  %32 = load i64, i64* %u, align 8
  %33 = load i64, i64* %u, align 8
  %34 = shl i64 %33, 16
  %35 = xor i64 %32, %34
  %36 = load i64, i64* %r, align 8
  %37 = xor i64 %35, %36
  %38 = load i32, i32* %i, align 4
  %39 = sext i32 %38 to i64
  %40 = load i64*, i64** %s, align 8
  %41 = getelementptr inbounds i64, i64* %40, i64 %39
  %42 = load i64, i64* %41, align 8
  %43 = xor i64 %37, %42
  store i64 %43, i64* %u, align 8
  %44 = load i64, i64* %t, align 8
  %45 = load i64, i64* %t, align 8
  %46 = shl i64 %45, 16
  %47 = xor i64 %44, %46
  %48 = load i64, i64* %r, align 8
  %49 = xor i64 %47, %48
  %50 = load i32, i32* %i, align 4
  %51 = add nsw i32 %50, 1
  %52 = sext i32 %51 to i64
  %53 = load i64*, i64** %s, align 8
  %54 = getelementptr inbounds i64, i64* %53, i64 %52
  %55 = load i64, i64* %54, align 8
  %56 = xor i64 %49, %55
  store i64 %56, i64* %t, align 8
  %57 = load i64, i64* %t, align 8
  %58 = lshr i64 %57, 4
  %59 = load i64, i64* %t, align 8
  %60 = shl i64 %59, 28
  %61 = or i64 %58, %60
  store i64 %61, i64* %t, align 8
  %62 = load i64, i64* %t, align 8
  %63 = and i64 %62, 63
  %64 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 1), i64 0, i64 %63
  %65 = load i64, i64* %64, align 8
  %66 = load i64, i64* %t, align 8
  %67 = lshr i64 %66, 8
  %68 = and i64 %67, 63
  %69 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 3), i64 0, i64 %68
  %70 = load i64, i64* %69, align 8
  %71 = or i64 %65, %70
  %72 = load i64, i64* %t, align 8
  %73 = lshr i64 %72, 16
  %74 = and i64 %73, 63
  %75 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 5), i64 0, i64 %74
  %76 = load i64, i64* %75, align 8
  %77 = or i64 %71, %76
  %78 = load i64, i64* %t, align 8
  %79 = lshr i64 %78, 24
  %80 = and i64 %79, 63
  %81 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 7), i64 0, i64 %80
  %82 = load i64, i64* %81, align 8
  %83 = or i64 %77, %82
  %84 = load i64, i64* %u, align 8
  %85 = and i64 %84, 63
  %86 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 0), i64 0, i64 %85
  %87 = load i64, i64* %86, align 8
  %88 = or i64 %83, %87
  %89 = load i64, i64* %u, align 8
  %90 = lshr i64 %89, 8
  %91 = and i64 %90, 63
  %92 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 2), i64 0, i64 %91
  %93 = load i64, i64* %92, align 8
  %94 = or i64 %88, %93
  %95 = load i64, i64* %u, align 8
  %96 = lshr i64 %95, 16
  %97 = and i64 %96, 63
  %98 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 4), i64 0, i64 %97
  %99 = load i64, i64* %98, align 8
  %100 = or i64 %94, %99
  %101 = load i64, i64* %u, align 8
  %102 = lshr i64 %101, 24
  %103 = and i64 %102, 63
  %104 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 6), i64 0, i64 %103
  %105 = load i64, i64* %104, align 8
  %106 = or i64 %100, %105
  %107 = load i64, i64* %l, align 8
  %108 = xor i64 %107, %106
  store i64 %108, i64* %l, align 8
  %109 = load i64, i64* %l, align 8
  %110 = load i64, i64* %l, align 8
  %111 = lshr i64 %110, 16
  %112 = xor i64 %109, %111
  store i64 %112, i64* %t, align 8
  %113 = load i64, i64* %t, align 8
  %114 = load i64, i64* %E0, align 8
  %115 = and i64 %113, %114
  store i64 %115, i64* %u, align 8
  %116 = load i64, i64* %t, align 8
  %117 = load i64, i64* %E1, align 8
  %118 = and i64 %116, %117
  store i64 %118, i64* %t, align 8
  %119 = load i64, i64* %u, align 8
  %120 = load i64, i64* %u, align 8
  %121 = shl i64 %120, 16
  %122 = xor i64 %119, %121
  %123 = load i64, i64* %l, align 8
  %124 = xor i64 %122, %123
  %125 = load i32, i32* %i, align 4
  %126 = add nsw i32 %125, 2
  %127 = sext i32 %126 to i64
  %128 = load i64*, i64** %s, align 8
  %129 = getelementptr inbounds i64, i64* %128, i64 %127
  %130 = load i64, i64* %129, align 8
  %131 = xor i64 %124, %130
  store i64 %131, i64* %u, align 8
  %132 = load i64, i64* %t, align 8
  %133 = load i64, i64* %t, align 8
  %134 = shl i64 %133, 16
  %135 = xor i64 %132, %134
  %136 = load i64, i64* %l, align 8
  %137 = xor i64 %135, %136
  %138 = load i32, i32* %i, align 4
  %139 = add nsw i32 %138, 2
  %140 = add nsw i32 %139, 1
  %141 = sext i32 %140 to i64
  %142 = load i64*, i64** %s, align 8
  %143 = getelementptr inbounds i64, i64* %142, i64 %141
  %144 = load i64, i64* %143, align 8
  %145 = xor i64 %137, %144
  store i64 %145, i64* %t, align 8
  %146 = load i64, i64* %t, align 8
  %147 = lshr i64 %146, 4
  %148 = load i64, i64* %t, align 8
  %149 = shl i64 %148, 28
  %150 = or i64 %147, %149
  store i64 %150, i64* %t, align 8
  %151 = load i64, i64* %t, align 8
  %152 = and i64 %151, 63
  %153 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 1), i64 0, i64 %152
  %154 = load i64, i64* %153, align 8
  %155 = load i64, i64* %t, align 8
  %156 = lshr i64 %155, 8
  %157 = and i64 %156, 63
  %158 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 3), i64 0, i64 %157
  %159 = load i64, i64* %158, align 8
  %160 = or i64 %154, %159
  %161 = load i64, i64* %t, align 8
  %162 = lshr i64 %161, 16
  %163 = and i64 %162, 63
  %164 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 5), i64 0, i64 %163
  %165 = load i64, i64* %164, align 8
  %166 = or i64 %160, %165
  %167 = load i64, i64* %t, align 8
  %168 = lshr i64 %167, 24
  %169 = and i64 %168, 63
  %170 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 7), i64 0, i64 %169
  %171 = load i64, i64* %170, align 8
  %172 = or i64 %166, %171
  %173 = load i64, i64* %u, align 8
  %174 = and i64 %173, 63
  %175 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 0), i64 0, i64 %174
  %176 = load i64, i64* %175, align 8
  %177 = or i64 %172, %176
  %178 = load i64, i64* %u, align 8
  %179 = lshr i64 %178, 8
  %180 = and i64 %179, 63
  %181 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 2), i64 0, i64 %180
  %182 = load i64, i64* %181, align 8
  %183 = or i64 %177, %182
  %184 = load i64, i64* %u, align 8
  %185 = lshr i64 %184, 16
  %186 = and i64 %185, 63
  %187 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 4), i64 0, i64 %186
  %188 = load i64, i64* %187, align 8
  %189 = or i64 %183, %188
  %190 = load i64, i64* %u, align 8
  %191 = lshr i64 %190, 24
  %192 = and i64 %191, 63
  %193 = getelementptr inbounds [64 x i64], [64 x i64]* getelementptr inbounds ([8 x [64 x i64]], [8 x [64 x i64]]* @SPtrans, i64 0, i64 6), i64 0, i64 %192
  %194 = load i64, i64* %193, align 8
  %195 = or i64 %189, %194
  %196 = load i64, i64* %r, align 8
  %197 = xor i64 %196, %195
  store i64 %197, i64* %r, align 8
  %200 = load i32, i32* %i, align 4
  %201 = add nsw i32 %200, 4
  store i32 %201, i32* %i, align 4
  %213 = load i64, i64* %r, align 8
  store i64 %213, i64* %t, align 8
  %214 = load i64, i64* %l, align 8
  %215 = lshr i64 %214, 1
  %216 = load i64, i64* %l, align 8
  %217 = shl i64 %216, 31
  %218 = or i64 %215, %217
  store i64 %218, i64* %r, align 8
  %219 = load i64, i64* %t, align 8
  %220 = lshr i64 %219, 1
  %221 = load i64, i64* %t, align 8
  %222 = shl i64 %221, 31
  %223 = or i64 %220, %222
  store i64 %223, i64* %l, align 8
  %224 = load i64, i64* %l, align 8
  %225 = and i64 %224, 4294967295
  store i64 %225, i64* %l, align 8
  %226 = load i64, i64* %r, align 8
  %227 = and i64 %226, 4294967295
  store i64 %227, i64* %r, align 8
  %228 = load i64, i64* %r, align 8
  %229 = lshr i64 %228, 1
  %230 = load i64, i64* %l, align 8
  %231 = xor i64 %229, %230
  %232 = and i64 %231, 1431655765
  store i64 %232, i64* %t, align 8
  %233 = load i64, i64* %t, align 8
  %234 = load i64, i64* %l, align 8
  %235 = xor i64 %234, %233
  store i64 %235, i64* %l, align 8
  %236 = load i64, i64* %t, align 8
  %237 = shl i64 %236, 1
  %238 = load i64, i64* %r, align 8
  %239 = xor i64 %238, %237
  store i64 %239, i64* %r, align 8
  %240 = load i64, i64* %l, align 8
  %241 = lshr i64 %240, 8
  %242 = load i64, i64* %r, align 8
  %243 = xor i64 %241, %242
  %244 = and i64 %243, 16711935
  store i64 %244, i64* %t, align 8
  %245 = load i64, i64* %t, align 8
  %246 = load i64, i64* %r, align 8
  %247 = xor i64 %246, %245
  store i64 %247, i64* %r, align 8
  %248 = load i64, i64* %t, align 8
  %249 = shl i64 %248, 8
  %250 = load i64, i64* %l, align 8
  %251 = xor i64 %250, %249
  store i64 %251, i64* %l, align 8
  %252 = load i64, i64* %r, align 8
  %253 = lshr i64 %252, 2
  %254 = load i64, i64* %l, align 8
  %255 = xor i64 %253, %254
  %256 = and i64 %255, 858993459
  store i64 %256, i64* %t, align 8
  %257 = load i64, i64* %t, align 8
  %258 = load i64, i64* %l, align 8
  %259 = xor i64 %258, %257
  store i64 %259, i64* %l, align 8
  %260 = load i64, i64* %t, align 8
  %261 = shl i64 %260, 2
  %262 = load i64, i64* %r, align 8
  %263 = xor i64 %262, %261
  store i64 %263, i64* %r, align 8
  %264 = load i64, i64* %l, align 8
  %265 = lshr i64 %264, 16
  %266 = load i64, i64* %r, align 8
  %267 = xor i64 %265, %266
  %268 = and i64 %267, 65535
  store i64 %268, i64* %t, align 8
  %269 = load i64, i64* %t, align 8
  %270 = load i64, i64* %r, align 8
  %271 = xor i64 %270, %269
  store i64 %271, i64* %r, align 8
  %272 = load i64, i64* %t, align 8
  %273 = shl i64 %272, 16
  %274 = load i64, i64* %l, align 8
  %275 = xor i64 %274, %273
  store i64 %275, i64* %l, align 8
  %276 = load i64, i64* %r, align 8
  %277 = lshr i64 %276, 4
  %278 = load i64, i64* %l, align 8
  %279 = xor i64 %277, %278
  %280 = and i64 %279, 252645135
  store i64 %280, i64* %t, align 8
  %281 = load i64, i64* %t, align 8
  %282 = load i64, i64* %l, align 8
  %283 = xor i64 %282, %281
  store i64 %283, i64* %l, align 8
  %284 = load i64, i64* %t, align 8
  %285 = shl i64 %284, 4
  %286 = load i64, i64* %r, align 8
  %287 = xor i64 %286, %285
  store i64 %287, i64* %r, align 8
  %288 = load i64, i64* %l, align 8
  %289 = load i64*, i64** %1, align 8
  store i64 %288, i64* %289, align 8
  %290 = load i64, i64* %r, align 8
  %291 = load i64*, i64** %2, align 8
  store i64 %290, i64* %291, align 8
  %82 = load i32, i32* %i, align 4
  %83 = icmp ult i32 %82, 8
  %86 = load i32, i32* %i, align 4
  %87 = zext i32 %86 to i64
  %88 = getelementptr inbounds [8 x i8], [8 x i8]* %key, i64 0, i64 %87
  store i8 0, i8* %88, align 1
  %145 = load i32, i32* %i, align 4
  %146 = icmp slt i32 %145, 16
  %1 = alloca i8*, align 8
  %2 = alloca i8*, align 8
  %i = alloca i32, align 4
  %j = alloca i32, align 4
  %x = alloca i32, align 4
  %y = alloca i32, align 4
  %Eswap0 = alloca i64, align 8
  %Eswap1 = alloca i64, align 8
  %out = alloca [2 x i64], align 16
  %ll = alloca i64, align 8
  %key = alloca [8 x i8], align 1
  %ks = alloca [16 x %struct.des_ks_struct], align 16
  %bb = alloca [9 x i8], align 1
  %b = alloca i8*, align 8
  %c = alloca i8, align 1
  %u = alloca i8, align 1
  store i8* %buf, i8** %1, align 8
  store i8* %salt, i8** %2, align 8
  store i64 0, i64* %Eswap0, align 8
  store i64 0, i64* %Eswap1, align 8
  %3 = getelementptr inbounds [9 x i8], [9 x i8]* %bb, i32 0, i32 0
  store i8* %3, i8** %b, align 8
  %4 = load i8*, i8** %2, align 8
  %5 = getelementptr inbounds i8, i8* %4, i64 0
  %6 = load i8, i8* %5, align 1
  %7 = sext i8 %6 to i32
  %8 = icmp eq i32 %7, 0
