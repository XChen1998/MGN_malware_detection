  store i8* %16, i8** %cp, align 8
  store i64 0, i64* %i, align 8
  store i64 0, i64* %j, align 8
  %20 = load i64, i64* %i, align 8
  %21 = load i64, i64* %2, align 8
  %22 = icmp ult i64 %20, %21
  %87 = load i32, i32* %i, align 4
  %88 = add nsw i32 %87, 2
  %89 = sext i32 %88 to i64
  %90 = load i8*, i8** %1, align 8
  %91 = getelementptr inbounds i8, i8* %90, i64 %89
  %92 = load i8, i8* %91, align 1
  %93 = zext i8 %92 to i32
  %94 = icmp eq i32 %93, 61
  %97 = load i32, i32* %i, align 4
  %98 = sext i32 %97 to i64
  %99 = load i8*, i8** %1, align 8
  %100 = getelementptr inbounds i8, i8* %99, i64 %98
  %101 = load i8, i8* %100, align 1
  %102 = zext i8 %101 to i64
  %103 = getelementptr inbounds [128 x i8], [128 x i8]* @ssh_inv_base64, i64 0, i64 %102
  %104 = load i8, i8* %103, align 1
  %105 = zext i8 %104 to i64
  %106 = shl i64 %105, 6
  %107 = load i32, i32* %i, align 4
  %108 = add nsw i32 %107, 1
  %109 = sext i32 %108 to i64
  %110 = load i8*, i8** %1, align 8
  %111 = getelementptr inbounds i8, i8* %110, i64 %109
  %112 = load i8, i8* %111, align 1
  %113 = zext i8 %112 to i64
  %114 = getelementptr inbounds [128 x i8], [128 x i8]* @ssh_inv_base64, i64 0, i64 %113
  %115 = load i8, i8* %114, align 1
  %116 = zext i8 %115 to i64
  %117 = or i64 %106, %116
  store i64 %117, i64* %limb, align 8
  %118 = load i64, i64* %limb, align 8
  %119 = lshr i64 %118, 4
  %120 = trunc i64 %119 to i8
  %121 = zext i8 %120 to i32
  %122 = and i32 %121, 255
  %123 = trunc i32 %122 to i8
  %124 = load i32, i32* %j, align 4
  %125 = sext i32 %124 to i64
  %126 = load i8*, i8** %buf, align 8
  %127 = getelementptr inbounds i8, i8* %126, i64 %125
  store i8 %123, i8* %127, align 1
  %128 = load i32, i32* %j, align 4
  %129 = add nsw i32 %128, 1
  store i32 %129, i32* %j, align 4
  store i64 %9, i64* %2, align 8
  %13 = load i64, i64* %2, align 8
  %14 = add i64 %13, 1
  %15 = call i8* @ssh_xmalloc(i64 %14)
  %25 = load i64, i64* %i, align 8
  %26 = load i8*, i8** %1, align 8
  %27 = getelementptr inbounds i8, i8* %26, i64 %25
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i32
  %30 = and i32 %29, 128
  %31 = icmp ne i32 %30, 0
  %13 = load i64, i64* %i, align 8
  %14 = add i64 %13, 2
  %15 = load i64, i64* %2, align 8
  %16 = icmp ult i64 %14, %15
  %19 = load i64, i64* %i, align 8
  %20 = load i8*, i8** %1, align 8
  %21 = getelementptr inbounds i8, i8* %20, i64 %19
  %22 = load i8, i8* %21, align 1
  %23 = zext i8 %22 to i64
  %24 = shl i64 %23, 16
  %25 = load i64, i64* %i, align 8
  %26 = add i64 %25, 1
  %27 = load i8*, i8** %1, align 8
  %28 = getelementptr inbounds i8, i8* %27, i64 %26
  %29 = load i8, i8* %28, align 1
  %30 = zext i8 %29 to i64
  %31 = shl i64 %30, 8
  %32 = or i64 %24, %31
  %33 = load i64, i64* %i, align 8
  %34 = add i64 %33, 2
  %35 = load i8*, i8** %1, align 8
  %36 = getelementptr inbounds i8, i8* %35, i64 %34
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i64
  %39 = or i64 %32, %38
  store i64 %39, i64* %limb, align 8
  %40 = load i64, i64* %limb, align 8
  %41 = lshr i64 %40, 18
  %42 = and i64 %41, 63
  %43 = getelementptr inbounds [64 x i8], [64 x i8]* @ssh_base64, i64 0, i64 %42
  %44 = load i8, i8* %43, align 1
  %45 = load i64, i64* %j, align 8
  %46 = load i8*, i8** %out, align 8
  %47 = getelementptr inbounds i8, i8* %46, i64 %45
  store i8 %44, i8* %47, align 1
  %48 = load i64, i64* %limb, align 8
  %49 = lshr i64 %48, 12
  %50 = and i64 %49, 63
  %51 = getelementptr inbounds [64 x i8], [64 x i8]* @ssh_base64, i64 0, i64 %50
  %52 = load i8, i8* %51, align 1
  %53 = load i64, i64* %j, align 8
  %54 = add i64 %53, 1
  %55 = load i8*, i8** %out, align 8
  %56 = getelementptr inbounds i8, i8* %55, i64 %54
  store i8 %52, i8* %56, align 1
  %57 = load i64, i64* %limb, align 8
  %58 = lshr i64 %57, 6
  %59 = and i64 %58, 63
  %60 = getelementptr inbounds [64 x i8], [64 x i8]* @ssh_base64, i64 0, i64 %59
  %61 = load i8, i8* %60, align 1
  %62 = load i64, i64* %j, align 8
  %63 = add i64 %62, 2
  %64 = load i8*, i8** %out, align 8
  %65 = getelementptr inbounds i8, i8* %64, i64 %63
  store i8 %61, i8* %65, align 1
  %66 = load i64, i64* %limb, align 8
  %67 = and i64 %66, 63
  %68 = getelementptr inbounds [64 x i8], [64 x i8]* @ssh_base64, i64 0, i64 %67
  %69 = load i8, i8* %68, align 1
  %70 = load i64, i64* %j, align 8
  %71 = add i64 %70, 3
  %72 = load i8*, i8** %out, align 8
  %73 = getelementptr inbounds i8, i8* %72, i64 %71
  store i8 %69, i8* %73, align 1
  %34 = load i64, i64* %i, align 8
  %35 = load i8*, i8** %1, align 8
  %36 = getelementptr inbounds i8, i8* %35, i64 %34
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i64
  %39 = getelementptr inbounds [128 x i8], [128 x i8]* @ssh_inv_base64, i64 0, i64 %38
  %40 = load i8, i8* %39, align 1
  %41 = zext i8 %40 to i32
  %42 = icmp ne i32 %41, 255
  %1 = alloca i8*, align 8
  %2 = alloca i64, align 8
  %i = alloca i64, align 8
  store i8* %buf, i8** %1, align 8
  store i64 %buf_len, i64* %2, align 8
  store i64 0, i64* %i, align 8
  %5 = load i64, i64* %i, align 8
  %6 = load i64, i64* %2, align 8
  %7 = icmp ult i64 %5, %6
  store i8* %9, i8** %out, align 8
  store i64 0, i64* %i, align 8
  store i64 0, i64* %j, align 8
  store i64 0, i64* %limb, align 8
  %45 = load i64, i64* %i, align 8
  %46 = load i8*, i8** %1, align 8
  %47 = getelementptr inbounds i8, i8* %46, i64 %45
  %48 = load i8, i8* %47, align 1
  %49 = zext i8 %48 to i32
  %50 = icmp eq i32 %49, 61
